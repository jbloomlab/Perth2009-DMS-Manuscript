\documentclass[11pt, oneside]{article}   	% use "amsart" instead of "article" for AMSLaTeX format
\usepackage{geometry}                		% See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   		% ... or a4paper or a5paper or ... 
\usepackage{color}
\usepackage[parfill]{parskip}    		% Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}				% Use pdf, png, jpg, or epsÂ§ with pdflatex; use eps in DVI mode
								% TeX will automatically convert eps --> pdf in pdflatex		
\usepackage{amssymb}

\newcommand{\comment}[1]{{\color{red}[\textsl{#1}]}}
\newcommand{\response}[1]{{\color{black}#1}}

\title{Response to reviews of ``Deep mutational scanning of hemagglutinin helps predict evolutionary fates of human H3N2 influenza variants'' for \textit{PNAS}}
\author{Juhye M. Lee, John Huddleston, Michael B. Doud, Kathryn A. Hooper,\\Nicholas C. Wu, Trevor Bedford, Jesse D. Bloom}

\begin{document}
\maketitle

We thank the reviewers for the careful reading and suggestions about the manuscript.
In the revised version, we have performed additional experiments and analyses that should address all of the reviewer concerns.

\emph{Below, the reviewer comments {\color{blue} are in blue}, and our responses are in black.}

\color{blue}

\subsection*{Reviewer \#1 Comments}

\subsubsection*{Comments:} 
In their manuscript Lee et al. examine the tolerance of an H3 virus HA for single point mutations using deep mutational scanning. Using the data obtained from cell culture experiments the authors then try to understand if there is a correlation between the observed changes in vitro and actual virus evolution in vivo. Finally, they test if there is any correlation between H3 and H1 mutational tolerance and basically find that measurements made with H1 HA are not helpful to predict H3 evolution. The manuscript is written in a relatively confusing way and the experimental setup is problematic. Some of the obtained data also need re-evaluation/experimental validation. 

\subsubsection*{Major points} 

1) It is disturbing that there is no preference for having a methionine in the first position of the HA ORF. The authors discuss this and refer to one 2002 paper that shows additional start sites for non-human H2. This is a pretty weak explanation. If this is really the case the authors should actually isolate/rescue these viruses and test their fitness relative to wild type. 

\comment{To reply to this point, we need to generate one of these mutants and show that it grows in cell culture.
{\bf Juhye:} we should discuss how to do this.}

Of note, position 1 for the H1 HA in the supplementary figure is not even shown. 

\response{Figure~S3 shows data for the H1 HA as measured previously by Doud and Bloom (2016). 
That study used mutant libraries in which all codons \emph{except} the one for the N-terminal methionine were mutagenized.
Therefore, that study did not estimate the effects of mutations to the first codon, which is why it is not shown in Figure~S3.
We have added a sentence to the legend for this supplementary figure explaining this fact.
}

2) While other important features of the HA like several cysteines seem to be conserved, there is no pressure on other elements which are considered important for viral fitness including the NGT glycosylation site in the beginning of HA1 which is conserved in all group 2 HAs or the adjacent NAT glycosylation site which is conserved in H3, H7, H10 and H15. On the other hand, head glycosylation sites, which are highly variable in nature, seem to be conserved. Again, viruses without these glycosylation sites should be rescued and evaluated for fitness relative to wild type. 

\comment{{\bf Juhye:} to reply to this point, we should generate several of these mutants and evaluate their growth in cell culture.}

3) It is also surprising that the transmembrane domain seems to be highly plastic, a feature that is certainly not present in nature where it is highly conserved within H3 HAs. 

\comment{Here we need to explain that constraint in our experiments and conservation in nature are not expected to be entirely the same.
Conservation in nature results from the convolution of constraint and diversifying selection from immunity, whereas our experiments only look at constraint.
As evidence to explain this point, we can point to studies showing that the head of HA is much more conserved for swine influenza viruses where there is less pressure from immunity.
{\bf Juhye:} To make this more convincing, we should also pick a site in the transmembrane domain that is highly conserved in nature but not under constraint in our experiments, and validate it.}

4) Were sequences from passaged viruses (isolated on MDCKs and other cell lines) included in the comparison between in vitro mutagenesis data and natural evolution data? They need to be excluded since their presence might induce a bias towards what is tolerated/preferred in cell culture. Only sequences obtained directly from patient specimens should be used for the comparison. 

\comment{This is a good suggestion. 
{\bf John:} I think we should add an additional analysis that does this only for sequences that were not passaged in cell-culture or eggs.
I believe that GISAID annotates passage history.
I would expect that we can only do this for the post-Perth sequences as I doubt that there are many unpasaged viruses prior to the early 2000's.
We could just add this as another panel assuming it gives the same results.}

5) It is unclear how the ``rescaling'' is performed and what it exactly does. The authors need to described and justify this better and should also provide the non-rescaled data in a ``sequence logo'' figure for comparison. 

\comment{This is easy to explain better; the only reason we didn't go into more detail before is because of space constraints.
We can also show the non-rescaled logo plots, as Supplemental Information.
I thought there was a limit on the number of Supplemental Information figures, but I can't find that right now so maybe we can just add them as more... If someone objects, we can then merge some of the SI figures into one large multi-panel figure.
We can explain how the scaling factor doesn't effect any of the evolutionary analyses as it is just a constant factor that multiplies all mutational effects, and so will therefore simply correspond to a change in units on the x-axis of the Figure~5.}

6) The authors state that it there are more reports of escape from stalk antibodies for H3 than H1. This is simply not true. Actually, the first reference used as evidence for easy selection of H3 anti-stalk escape mutants (Chai et al) reported three escape mutants which a) did not disrupt binding completely and b) were crippled in vitro and in vivo. The authors should remove their statement as there is not systematic data to support this. 

\comment{We looked at this pretty carefully, and there are definitely more reports of selecting anti-stalk antibodies for H1 and H3.
The reviewer's counterpoint is to mention on of the H3 studies. 
However, we didn't say that there are no H3 reports, just that there are a lot more H1 reports.
Certainly this is not systematic proof, but our statement in the text goes to great pains to caveat that this is purely circumstantial and not systematic proof.
But since this isn't a central claim of the paper of anyway, let's just remove it in a concession to the reviewer.
The study we're helping Nicholas Wu with will eventually systematically test this point.
}

7) The biggest issue with the manuscript is the experimental set up. The authors titrate their rescued virus using a TCID50 assay on MDCK cells. Based on the titer that they measure, they passage the virus from the initial rescue once onto fresh MDCK cells using a low MOI. After infection, the virus dilution stays on the cells and is then harvested without centrifugation followed by RNA extraction and sequencing. There are many issue with this process. 

\response{The reviewer has a number of questions and suggestions about the experimental design.
Over the last few years, we have performed a number of studies optimizing procedures for deep mutational scanning of influenza virus libraries (see PMIDs 24859245, 25006036, 27271655) during which we have carefully considered all of the experimental parameters that the reviewer discusses.
Below we briefly explain why each of our choices for these experimental parameters were appropriate.
We do not deny that there are slightly different ways that the experiments could be done, but the in end, the ``proof is in the pudding.'' 
In the manuscript, we show that the measurements made using the experimental parameters that we chose lead to useful data as judged by the following criterion:
\begin{itemize}
\item The results from fully independent experimental replicates are highly correlated (Fig.~1D), which would not be the case if the results were dominated by noise.
\item The experimental measurements do a good job of predicting the effects of individually validated mutations \comment{Here we would refer to the validation experiments described above}.
\item The experimental measurements can inform substitution models that describe influenza virus's evolution much better than standard models (Table~1).
\item The experimental measurements provide information that can help predict the fates of influenza virus lineages in nature (Fig.~5).
\end{itemize}
We do not claim that other experimental parameter choices might not lead to equivalent or even slightly better results, but we have carefully considered all of our choices and clearly they lead to very good results.

Below we explain our reasoning for each choice about which the reviewer makes suggestions:
}

a) The TCID50 is likely underestimating the number of virus particles with HA genomic segments because not all of them (likely the minority) will be capable of inducting a full infectious cycle (but their presence might still be detected in the cell supernatants). 

\response{The reviewer is certainly correct that TCID50 assays underestimate the number of HA genomic segments, as it is well known that the number of physical influenza virions exceeds the number of infectious units by 10-100 fold.
This is why we used an extremely low MOI (0.0035) so that most cells are still infected by no more than one virion.
It is impossible to ever grow a viral stock that is completely free of defective particles.
However, in both our original rescue with helper virus and in the passage, we follow the steps suggested by Carolina Lopez and Scott Hensley (PMID 27047455) to minimize defective particles.
These include low MOI (0.0035 TCID50 per cell is quite low), and short growth times to avoid accumulation of defective particles (the helper-virus rescue was allowed to propagate for just 24 hours, and the low-MOI passage for just 48 hours).
\comment{Juhye, do you have HA-staining titers for these viruses too? Then we can explicitly compare HA-expressing units to TCID50.}
}

b) The infectious inoculum is never washed off the infected cells meaning that any particles that are transferred from the rescue transfection are going to be detected during sequencing. This might even apply to naked RNPs released from dead cells. 

\response{It is true that the original inoculum remains and so will contribute to the variants detected during sequencing.
However, the original inoculum makes a negligible contribution to the total number of virions that are present at the time of sequencing.
Specifically, in the original inoculum placed on the cells, the titer is \comment{?} TCID50 / ml, whereas at the time of supernatant collection for sequencing the titer is \comment{?} TCID50 / ml.
Therefore, the original inoculum constitutes just \comment{?}\% of the viral titer at the time of collection, and therefore makes a negligible contribution to the sequenced material.
\comment{Juhye, can you calculate these numbers from the TCID50 of the collected viruses. 
You can also mention those titers in the Methods.
I expect that we will see at least a 10,000-fold dilution of the original inoculum.
If we really want to nail this point (and the one after it), we could also do qPCR on the inoculum (we could re-constitute some from a bit of transfection supernatant) and the passage supernatant to show that the HA RNA amounts also changed comparably.
I don't think this is really necessary since it's obvious, but we could do it if we want to really drive a stake through the heart of the reviewers' concern...}
}

c) This would actually not be an issue, if the dilution from the rescue culture to the new culture would be large enough. But this is not the case. The authors passaged $9\times10^5$ TCID50 (and likely much more DIs/RNA) from the rescue cultures onto the new cells in a volume of 25 ml. This is, depending on experiment, between 10 and 1 ml of supernatant of the original rescue and leads to a 1:2.5 or 1:25 dilution respectively. 

\comment{The reviewer's math is off here, we passaged $9\times 10^5$ TCID50 \emph{total} across all 15 cm dishes. 
This could be clarified by adding a word to the Methods indicating how many 15-cm dishes we used (right now, it just says ``in 15-cm dishes.''
Below that we say that we used an inoculum of 2.5 TCID50 / $\mu$l, which corresponds to dilutions that range from 1:37 to 1:294, not 1:2.5 or 1:25 as the reviewer says.
In addition, we should point out that the supernatant comes from a helper-virus rescue that has occurred for just 24 hours, and so has low titers of both infectious virus and TCID50s.
Again, we could really drive a stake through this question by doing the qPCR mentioned above.
}

d) The supernatant is never centrifuged before RNA extraction. Cell debris is not removed which is likely contributing significantly to RNA sequences detected in the supernatant. However, RNA associated with cell debris is not representative of RNA from fit, replicating viruses. 

\response{The reviewer is correct that we never clarified the viral supernatant before RNA extraction.
There are two reason for this.
First, for a relatively short and very low MOI passage like the one we used (48 hours starting at a MOI of 0.0035), there was little cell debri since the cell monolayer was still largely intact at the end of the passage.
Second, there is no reason to expect that the RNA in supernatant virions will better correspond to functional HA mutants that RNA in cell debris.
If anything, the opposite might be expected.
Functional HA is needed only for viral entry.
The RNA in cell debris at least originated from a virus that was able to enter the cell, whereas the HA in released virions has not yet undergone selection beyond that which occurred at the infection stage.
In practice, after 48 hours, most RNA is from viruses that have undergone multiple cycles of infection, and so there has been reasonably strong selection for HA function in both virion RNA and cell debris RNA.
}

The experiments should be repeated with at least one more passaging step, proper removal of inoculum and washing of the cells after infection. Centrifugation steps should also be included between the passages and before RNA extraction in the end. 

\response{For the reasons described above, it is not necessary to totally repeat the experiments.
Certainly other experimental parameter choices could have been used, but this is always the case for complex experiments.
Our choices will reasonable, and the four lines of evidence listed at the beginning of this comment show that they yield reproducible and meaningful results.}

\subsubsection*{Minor points} 

1) Many abbreviations are not defined in the manuscript including MDCK-SIAT1, TMPRSS2, MOI, DMEM, FBS, LB. 

2) The authors state on page 5 that mutations detected in cell culture as deleterious rarely reach high frequency in nature. Could you please give a few examples? 

3) The authors picked 31 random clones to evaluate the mutation rate per clone. These sequences should be made available. Did this set include viruses without a proper start codon (see above)? What was their growth phenotype in vitro? 

\subsection*{Reviewer \#2 Comments} 

\subsubsection*{Comments:} 
The work presented in this manuscript is a thorough analysis of the tolerance of an H3 hemagglutinin to all possible single amino-acid mutations. H3 evolution is of particular relevance now in light of the most recent flu season where vaccine efficacy against H3N2 was estimated at only 25\%. The experimental setup presented in the manuscript is sound and there is strong correlation among the biological and technical replicates. The authors show that data from deep mutational scanning is better able to describe the evolution of H3 HA compared to conventional models. This is consistent with the results of their previous study using deep mutational scanning on the H1 HA of WSN. It is important to note that their approach is "systematic and quantitative" in capturing potential effects of mutations in the H3 HA on viral fitness in cell culture. The significance statement is accurate in describing the conclusions of the paper and is understandable to a general scientific audience. 

\subsubsection*{Major points:} 

The authors themselves acknowledge the most important limitation of this study: that the experimental measure of viral growth in cell culture is not reflective of true fitness in nature. Most importantly, the work presented here does not capture host-induced pressures on the antigenic regions of the viral protein. This is evidenced by the discrepancy between the high mutational tolerance they calculated for the stalk region and the actual change in stalk amino acid sequence. A simple protein BLAST comparison between the amino acid sequences of HA from H3N2 viruses Perth09 and HK68 shows a 77\% conservation in head amino acids but a 94\% conservation in stalk amino acids. Additionally, according to figure 2, there is no observable reversion of the G78D mutation they introduced despite the dominance of G78 in the population as seen in figure S1. The authors recognize this in their work and do not attempt to exaggerate the significance of these findings. Still, it would be useful to differentiate between head and stalk mutations when depicting individual amino acid mutations in figure 4 and their frequency trajectories to highlight that the predominance of mutations that occur in nature are in the head. 

The data regarding greater mutational tolerance in the stalk compared to the head should be paired with data from deep mutational scanning utilizing stalk- and head-specific antibodies as a selection process as this group has previously done with WSN H1 (Doud et al., Nat Comm 2018, Doud et al., PLoS Path 2017) to see if tolerant sites are responsible for viral escape. 

Additionally, the authors should directly show the discrepancies between this in vitro selection and the H3 HA's evolution in nature. This group has performed such an analysis in their previous deep mutational scanning work with the H1 HA of WSN (Doud and Bloom, Viruses 2016). Maximum likelihood phylogenetics can be used to estimate the difference between experimental amino acid preference and natural preference. One might expect that this would provide some insight into the nature of the bias introduced through cell culture. 

The authors are upfront about the limited degree to which their calculated mutational effect and the maximum mutation frequency in nature correlate, describing it as "modest." One of the major points of the paper is that conclusions from this type of analysis cannot be generalized when using data from strains that are too divergent. The authors should address the possibility that data from deep mutational scanning can be generalized to divergent strains if the study is done in a system that is more reflective of nature. 

The experimental approach of deep mutational scanning has been applied to viral proteins before, including HIV env, influenza H1 HA, and NP. The novelty in this paper is that it is the first time such an analysis has been performed for H3 specifically and that it demonstrates the (albeit limited) utility of deep mutational scanning in predicting the success of viral strains in nature. Ultimately, it is clear from the discussion that the authors see this study as an intermediate step, suggesting that their work is "an improvement over no information at all." While something is indeed better than nothing, in my opinion, this paper represents only an incremental step forward in the field of influenza evolutionary forecasting due to the aforementioned limitations, especially since this experiment and subsequent analysis could be performed using more stringent selection methods during viral passaging like treatment with human sera for data that is presumably more faithful to nature. 

\subsubsection*{Minor Points:} 

The correlation for prospective analysis (post-Perth) is smaller than the correlation for post-hoc analysis (pre-Perth). Since prospective analysis is more important when predicting evolutionary fates, it might be beneficial for the authors to comment on this difference. 

A number of issues interfere with the clarity of this manuscript, particularly when appealing to a broader scientific audience. While this is understandable given the nature of this study, several adjustments should be made. A clear description of mutational effect is never provided in the results, though it forms a crucial component of the data. As such, it is not really intuitive as to why the range from -10-0 should be considered "neutral." Additionally, mutational tolerance is quantified as Shannon entropy of the re-scaled amino-acid preferences at each site, but it is unclear how this entropy is calculated. The entire first half of the second results section describing how the experimentally informed codon substitution model they generate is better than existing models and the associated Table 1 is very difficult to understand. AIC is never explained. The significance of dN/dS being much less than 1 for conventional models should be explained. The purpose of modeling of ExpCM, site avg. is unclear. 
In figure 4, it would be useful to show Perth09 on the tree and mention that closely related strains are excluded from analysis in the figure legend. As it stands, there is just an unlabeled cluster of viruses for which no individual amino acid mutations are characterized. It is also important for the authors to clearly state what frequency they are talking about. Specifically, in consideration of a particular mutation, what is the population in the denominator? 

The graph labels in figure 8B could be cleaner. The question marks after "absolutely conserved" and "clade-specific" are extraneous. Indeed, the graph labels themselves ("HA domain," "absolutely conserved? ""clade-specific?") are unnecessary. 





\end{document}  